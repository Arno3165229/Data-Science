{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzqY57tfKXdd"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGps6lbqN-Q5"
   },
   "outputs": [],
   "source": [
    "def split_train_val_id(n, val_percent=0.1):\n",
    "    ids = [i for i in range(n)]\n",
    "    random.shuffle(ids)\n",
    "    piv = int(n*val_percent)\n",
    "    if piv==0: \n",
    "        piv=1\n",
    "    return {'train': ids[:-piv], 'val': ids[-piv:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGk7pbpLN_Ro"
   },
   "outputs": [],
   "source": [
    "datas = np.load('train_features.npy')\n",
    "labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeeNuyd_OAK6"
   },
   "outputs": [],
   "source": [
    "NUM_DATA_USE = 5000\n",
    "INPUT_DIM_1D = datas.shape[1]*datas.shape[2]\n",
    "OUTPUT_DIM = labels.shape[1]-1\n",
    "val_percent = 0.2\n",
    "\n",
    "train_val_id = split_train_val_id(NUM_DATA_USE, val_percent)\n",
    "train_id = train_val_id['train']\n",
    "val_id = train_val_id['val']\n",
    "\n",
    "train_datas = np.zeros((len(train_id), INPUT_DIM_1D))\n",
    "train_labels = np.zeros((len(train_id), OUTPUT_DIM))\n",
    "for i, idx in enumerate(train_id):\n",
    "    train_datas[i] = datas[idx].reshape(INPUT_DIM_1D)\n",
    "    train_labels[i] = labels[idx][1:]\n",
    "    \n",
    "#reduce data information\n",
    "train_datas = train_datas[:, :10000]\n",
    "\n",
    "\n",
    "# #seven labels\n",
    "day1_labels = np.zeros(len(train_id))\n",
    "day2_labels = np.zeros(len(train_id))\n",
    "day3_labels = np.zeros(len(train_id))\n",
    "day4_labels = np.zeros(len(train_id))\n",
    "day5_labels = np.zeros(len(train_id))\n",
    "day6_labels = np.zeros(len(train_id))\n",
    "day7_labels = np.zeros(len(train_id))\n",
    "\n",
    "for i in range(len(train_id)):\n",
    "    if train_labels[i, :4].sum()!=0:\n",
    "        day1_labels[i] = 1\n",
    "    if train_labels[i, 4:8].sum()!=0:\n",
    "        day2_labels[i] = 1\n",
    "    if train_labels[i, 8:12].sum()!=0:\n",
    "        day3_labels[i] = 1\n",
    "    if train_labels[i, 12:16].sum()!=0:\n",
    "        day4_labels[i] = 1\n",
    "    if train_labels[i, 16:20].sum()!=0:\n",
    "        day5_labels[i] = 1\n",
    "    if train_labels[i, 20:24].sum()!=0:\n",
    "        day6_labels[i] = 1\n",
    "    if train_labels[i, 24:28].sum()!=0:\n",
    "        day7_labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kZSKTUdOBpz"
   },
   "outputs": [],
   "source": [
    "NUM_OF_VAL = len(val_id)\n",
    "val_datas = np.zeros((NUM_OF_VAL, INPUT_DIM_1D))\n",
    "val_labels = np.zeros((NUM_OF_VAL, OUTPUT_DIM))\n",
    "for i, idx in enumerate(val_id):\n",
    "    val_datas[i] = datas[idx].reshape(INPUT_DIM_1D)\n",
    "    val_labels[i] = labels[idx][1:]\n",
    "    \n",
    "#reduce data information\n",
    "val_datas = val_datas[:, :10000]\n",
    "\n",
    "# #seven labels\n",
    "val_day1_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day2_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day3_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day4_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day5_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day6_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day7_labels = np.zeros(NUM_OF_VAL)\n",
    "\n",
    "for i in range(NUM_OF_VAL):\n",
    "    if val_labels[i, :4].sum()!=0:\n",
    "        val_day1_labels[i] = 1\n",
    "    if val_labels[i, 4:8].sum()!=0:\n",
    "        val_day2_labels[i] = 1\n",
    "    if val_labels[i, 8:12].sum()!=0:\n",
    "        val_day3_labels[i] = 1\n",
    "    if val_labels[i, 12:16].sum()!=0:\n",
    "        val_day4_labels[i] = 1\n",
    "    if val_labels[i, 16:20].sum()!=0:\n",
    "        val_day5_labels[i] = 1\n",
    "    if val_labels[i, 20:24].sum()!=0:\n",
    "        val_day6_labels[i] = 1\n",
    "    if val_labels[i, 24:28].sum()!=0:\n",
    "        val_day7_labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPrwGmFYODpD"
   },
   "outputs": [],
   "source": [
    "def proba2onehot(pred, length, threshold):\n",
    "    for i in range(length):\n",
    "        if pred[i]>=threshold:\n",
    "            pred[i] = 1\n",
    "        else:\n",
    "            pred[i] = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "0aNp4raVOE1E",
    "outputId": "ac6487a3-30ed-45b1-c657-fe72baead903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 1, 200)            6120600   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 100)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 6,220,059\n",
      "Trainable params: 6,219,867\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=200, input_shape=(1, train_datas.shape[1]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7, activation = \"relu\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1054
    },
    "colab_type": "code",
    "id": "u-4MhTmeOIae",
    "outputId": "3fe7dced-a556-4613-b522-42cea99389a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.5136 - val_loss: 0.2221\n",
      "Epoch 2/30\n",
      "4000/4000 [==============================] - 3s 653us/step - loss: 0.2677 - val_loss: 0.1933\n",
      "Epoch 3/30\n",
      "4000/4000 [==============================] - 3s 654us/step - loss: 0.2247 - val_loss: 0.1698\n",
      "Epoch 4/30\n",
      "4000/4000 [==============================] - 3s 653us/step - loss: 0.2034 - val_loss: 0.1552\n",
      "Epoch 5/30\n",
      "4000/4000 [==============================] - 3s 646us/step - loss: 0.1929 - val_loss: 0.1438\n",
      "Epoch 6/30\n",
      "4000/4000 [==============================] - 3s 650us/step - loss: 0.1789 - val_loss: 0.1373\n",
      "Epoch 7/30\n",
      "4000/4000 [==============================] - 3s 651us/step - loss: 0.1696 - val_loss: 0.1303\n",
      "Epoch 8/30\n",
      "4000/4000 [==============================] - 3s 658us/step - loss: 0.1610 - val_loss: 0.1269\n",
      "Epoch 9/30\n",
      "4000/4000 [==============================] - 3s 652us/step - loss: 0.1522 - val_loss: 0.1286\n",
      "Epoch 10/30\n",
      "4000/4000 [==============================] - 3s 670us/step - loss: 0.1479 - val_loss: 0.1277\n",
      "Epoch 11/30\n",
      "4000/4000 [==============================] - 3s 668us/step - loss: 0.1445 - val_loss: 0.1261\n",
      "Epoch 12/30\n",
      "4000/4000 [==============================] - 3s 669us/step - loss: 0.1419 - val_loss: 0.1272\n",
      "Epoch 13/30\n",
      "4000/4000 [==============================] - 3s 641us/step - loss: 0.1395 - val_loss: 0.1265\n",
      "Epoch 14/30\n",
      "4000/4000 [==============================] - 3s 636us/step - loss: 0.1372 - val_loss: 0.1243\n",
      "Epoch 15/30\n",
      "4000/4000 [==============================] - 3s 639us/step - loss: 0.1372 - val_loss: 0.1231\n",
      "Epoch 16/30\n",
      "4000/4000 [==============================] - 3s 638us/step - loss: 0.1320 - val_loss: 0.1238\n",
      "Epoch 17/30\n",
      "4000/4000 [==============================] - 3s 634us/step - loss: 0.1340 - val_loss: 0.1229\n",
      "Epoch 18/30\n",
      "4000/4000 [==============================] - 3s 639us/step - loss: 0.1327 - val_loss: 0.1239\n",
      "Epoch 19/30\n",
      "4000/4000 [==============================] - 3s 631us/step - loss: 0.1319 - val_loss: 0.1230\n",
      "Epoch 20/30\n",
      "4000/4000 [==============================] - 3s 633us/step - loss: 0.1321 - val_loss: 0.1220\n",
      "Epoch 21/30\n",
      "4000/4000 [==============================] - 3s 633us/step - loss: 0.1304 - val_loss: 0.1229\n",
      "Epoch 22/30\n",
      "4000/4000 [==============================] - 3s 641us/step - loss: 0.1313 - val_loss: 0.1197\n",
      "Epoch 23/30\n",
      "4000/4000 [==============================] - 3s 635us/step - loss: 0.1290 - val_loss: 0.1208\n",
      "Epoch 24/30\n",
      "4000/4000 [==============================] - 3s 639us/step - loss: 0.1261 - val_loss: 0.1208\n",
      "Epoch 25/30\n",
      "4000/4000 [==============================] - 3s 638us/step - loss: 0.1272 - val_loss: 0.1202\n",
      "Epoch 26/30\n",
      "4000/4000 [==============================] - 3s 637us/step - loss: 0.1282 - val_loss: 0.1205\n",
      "Epoch 27/30\n",
      "4000/4000 [==============================] - 3s 641us/step - loss: 0.1286 - val_loss: 0.1225\n",
      "Epoch 28/30\n",
      "4000/4000 [==============================] - 3s 635us/step - loss: 0.1259 - val_loss: 0.1190\n",
      "Epoch 29/30\n",
      "4000/4000 [==============================] - 3s 636us/step - loss: 0.1249 - val_loss: 0.1202\n",
      "Epoch 30/30\n",
      "4000/4000 [==============================] - 3s 641us/step - loss: 0.1219 - val_loss: 0.1191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2132b3a20>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(train_datas, (train_datas.shape[0], 1, train_datas.shape[1]))\n",
    "X_val = np.reshape(val_datas, (val_datas.shape[0], 1, val_datas.shape[1]))\n",
    "all_day_labels=np.concatenate((day1_labels.reshape(4000,1),day2_labels.reshape(4000,1),day3_labels.reshape(4000,1),day4_labels.reshape(4000,1),day5_labels.reshape(4000,1),day6_labels.reshape(4000,1),day7_labels.reshape(4000,1)),axis=1)\n",
    "val_all_day_labels=np.concatenate((val_day1_labels.reshape(1000,1),val_day2_labels.reshape(1000,1),val_day3_labels.reshape(1000,1),val_day4_labels.reshape(1000,1),val_day5_labels.reshape(1000,1),val_day6_labels.reshape(1000,1),val_day7_labels.reshape(1000,1)),axis=1)\n",
    "model.fit(X_train, all_day_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_data = (X_val, val_all_day_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "hwwx_dKXOKHv",
    "outputId": "7c369646-164a-4eeb-a1ef-ca5527e4ffd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.94      0.90      5302\n",
      "         1.0       0.75      0.53      0.62      1698\n",
      "\n",
      "    accuracy                           0.84      7000\n",
      "   macro avg       0.80      0.74      0.76      7000\n",
      "weighted avg       0.83      0.84      0.83      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (NUM_OF_VAL*7))\n",
    "y_pred = proba2onehot(y_pred, NUM_OF_VAL*7, THRESHOLD)\n",
    "print(classification_report(val_all_day_labels.reshape(7000), y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "RxlZASoJOLNl",
    "outputId": "58e16874-ce70-438c-d930-04b19dd8fb09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 1, 200)            6120600   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 100)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 6,211,607\n",
      "Trainable params: 6,211,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=200, input_shape=(1, train_datas.shape[1]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7, activation = \"relu\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "Yc0jS_q7OM3Z",
    "outputId": "dca090cc-13d2-455c-b183-3c97b84715d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.1910 - val_loss: 0.1340\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 2s 524us/step - loss: 0.1407 - val_loss: 0.1295\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 2s 531us/step - loss: 0.1340 - val_loss: 0.1231\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 2s 525us/step - loss: 0.1265 - val_loss: 0.1216\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 2s 540us/step - loss: 0.1245 - val_loss: 0.1223\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 2s 523us/step - loss: 0.1226 - val_loss: 0.1203\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 2s 524us/step - loss: 0.1202 - val_loss: 0.1179\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 2s 532us/step - loss: 0.1160 - val_loss: 0.1187\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 2s 531us/step - loss: 0.1146 - val_loss: 0.1136\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 2s 532us/step - loss: 0.1139 - val_loss: 0.1174\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 2s 527us/step - loss: 0.1137 - val_loss: 0.1171\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 2s 525us/step - loss: 0.1136 - val_loss: 0.1156\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 2s 521us/step - loss: 0.1121 - val_loss: 0.1156\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 2s 528us/step - loss: 0.1116 - val_loss: 0.1170\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 2s 535us/step - loss: 0.1108 - val_loss: 0.1165\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 2s 531us/step - loss: 0.1098 - val_loss: 0.1150\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 2s 529us/step - loss: 0.1083 - val_loss: 0.1140\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 2s 528us/step - loss: 0.1087 - val_loss: 0.1140\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 2s 520us/step - loss: 0.1077 - val_loss: 0.1153\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 2s 529us/step - loss: 0.1083 - val_loss: 0.1154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1f1b34860>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(train_datas, (train_datas.shape[0], 1, train_datas.shape[1]))\n",
    "X_val = np.reshape(val_datas, (val_datas.shape[0], 1, val_datas.shape[1]))\n",
    "all_day_labels=np.concatenate((day1_labels.reshape(4000,1),day2_labels.reshape(4000,1),day3_labels.reshape(4000,1),day4_labels.reshape(4000,1),day5_labels.reshape(4000,1),day6_labels.reshape(4000,1),day7_labels.reshape(4000,1)),axis=1)\n",
    "val_all_day_labels=np.concatenate((val_day1_labels.reshape(1000,1),val_day2_labels.reshape(1000,1),val_day3_labels.reshape(1000,1),val_day4_labels.reshape(1000,1),val_day5_labels.reshape(1000,1),val_day6_labels.reshape(1000,1),val_day7_labels.reshape(1000,1)),axis=1)\n",
    "model.fit(X_train, all_day_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_data = (X_val, val_all_day_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "5LVMm-FFOOZE",
    "outputId": "c4650642-131d-4eb4-9a62-33059f637dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90      5302\n",
      "         1.0       0.71      0.59      0.65      1698\n",
      "\n",
      "    accuracy                           0.84      7000\n",
      "   macro avg       0.80      0.76      0.77      7000\n",
      "weighted avg       0.84      0.84      0.84      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (NUM_OF_VAL*7))\n",
    "y_pred = proba2onehot(y_pred, NUM_OF_VAL*7, THRESHOLD)\n",
    "print(classification_report(val_all_day_labels.reshape(7000), y_pred)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data_science_final_project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
