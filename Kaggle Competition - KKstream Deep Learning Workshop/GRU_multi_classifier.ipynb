{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_id(n, val_percent=0.1):\n",
    "    ids = [i for i in range(n)]\n",
    "    random.shuffle(ids)\n",
    "    piv = int(n*val_percent)\n",
    "    if piv==0: \n",
    "        piv=1\n",
    "    return {'train': ids[:-piv], 'val': ids[-piv:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = np.load('train_features.npy')\n",
    "labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DATA_USE = 5000\n",
    "INPUT_DIM_1D = datas.shape[1]*datas.shape[2]\n",
    "OUTPUT_DIM = labels.shape[1]-1\n",
    "val_percent = 0.2\n",
    "\n",
    "train_val_id = split_train_val_id(NUM_DATA_USE, val_percent)\n",
    "train_id = train_val_id['train']\n",
    "val_id = train_val_id['val']\n",
    "\n",
    "train_datas = np.zeros((len(train_id), INPUT_DIM_1D))\n",
    "train_labels = np.zeros((len(train_id), OUTPUT_DIM))\n",
    "for i, idx in enumerate(train_id):\n",
    "    train_datas[i] = datas[idx].reshape(INPUT_DIM_1D)\n",
    "    train_labels[i] = labels[idx][1:]\n",
    "    \n",
    "#reduce data information\n",
    "train_datas = train_datas[:, :10000]\n",
    "\n",
    "\n",
    "# #seven labels\n",
    "day1_labels = np.zeros(len(train_id))\n",
    "day2_labels = np.zeros(len(train_id))\n",
    "day3_labels = np.zeros(len(train_id))\n",
    "day4_labels = np.zeros(len(train_id))\n",
    "day5_labels = np.zeros(len(train_id))\n",
    "day6_labels = np.zeros(len(train_id))\n",
    "day7_labels = np.zeros(len(train_id))\n",
    "\n",
    "for i in range(len(train_id)):\n",
    "    if train_labels[i, :4].sum()!=0:\n",
    "        day1_labels[i] = 1\n",
    "    if train_labels[i, 4:8].sum()!=0:\n",
    "        day2_labels[i] = 1\n",
    "    if train_labels[i, 8:12].sum()!=0:\n",
    "        day3_labels[i] = 1\n",
    "    if train_labels[i, 12:16].sum()!=0:\n",
    "        day4_labels[i] = 1\n",
    "    if train_labels[i, 16:20].sum()!=0:\n",
    "        day5_labels[i] = 1\n",
    "    if train_labels[i, 20:24].sum()!=0:\n",
    "        day6_labels[i] = 1\n",
    "    if train_labels[i, 24:28].sum()!=0:\n",
    "        day7_labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_VAL = len(val_id)\n",
    "val_datas = np.zeros((NUM_OF_VAL, INPUT_DIM_1D))\n",
    "val_labels = np.zeros((NUM_OF_VAL, OUTPUT_DIM))\n",
    "for i, idx in enumerate(val_id):\n",
    "    val_datas[i] = datas[idx].reshape(INPUT_DIM_1D)\n",
    "    val_labels[i] = labels[idx][1:]\n",
    "    \n",
    "#reduce data information\n",
    "val_datas = val_datas[:, :10000]\n",
    "\n",
    "# #seven labels\n",
    "val_day1_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day2_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day3_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day4_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day5_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day6_labels = np.zeros(NUM_OF_VAL)\n",
    "val_day7_labels = np.zeros(NUM_OF_VAL)\n",
    "\n",
    "for i in range(NUM_OF_VAL):\n",
    "    if val_labels[i, :4].sum()!=0:\n",
    "        val_day1_labels[i] = 1\n",
    "    if val_labels[i, 4:8].sum()!=0:\n",
    "        val_day2_labels[i] = 1\n",
    "    if val_labels[i, 8:12].sum()!=0:\n",
    "        val_day3_labels[i] = 1\n",
    "    if val_labels[i, 12:16].sum()!=0:\n",
    "        val_day4_labels[i] = 1\n",
    "    if val_labels[i, 16:20].sum()!=0:\n",
    "        val_day5_labels[i] = 1\n",
    "    if val_labels[i, 20:24].sum()!=0:\n",
    "        val_day6_labels[i] = 1\n",
    "    if val_labels[i, 24:28].sum()!=0:\n",
    "        val_day7_labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba2onehot(pred, length, threshold):\n",
    "    for i in range(length):\n",
    "        if pred[i]>=threshold:\n",
    "            pred[i] = 1\n",
    "        else:\n",
    "            pred[i] = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_25 (GRU)                 (None, 1, 200)            6120600   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (None, 100)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,219,861\n",
      "Trainable params: 6,219,669\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=200, input_shape=(1, train_datas.shape[1]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"relu\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "4000/4000 [==============================] - 25s 6ms/step - loss: 0.4772 - val_loss: 0.2346\n",
      "Epoch 2/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.2607 - val_loss: 0.2076\n",
      "Epoch 3/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.2382 - val_loss: 0.1868\n",
      "Epoch 4/30\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.2128 - val_loss: 0.1913\n",
      "Epoch 5/30\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.2157 - val_loss: 0.2007\n",
      "Epoch 6/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.2107 - val_loss: 0.1495\n",
      "Epoch 7/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.2079 - val_loss: 0.1783\n",
      "Epoch 8/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1898 - val_loss: 0.1477\n",
      "Epoch 9/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1770 - val_loss: 0.1347\n",
      "Epoch 10/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1743 - val_loss: 0.1350\n",
      "Epoch 11/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1647 - val_loss: 0.1272\n",
      "Epoch 12/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1553 - val_loss: 0.1291\n",
      "Epoch 13/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1429 - val_loss: 0.1249\n",
      "Epoch 14/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1433 - val_loss: 0.1229\n",
      "Epoch 15/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1353 - val_loss: 0.1237\n",
      "Epoch 16/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1319 - val_loss: 0.1229\n",
      "Epoch 17/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1290 - val_loss: 0.1244\n",
      "Epoch 18/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1335 - val_loss: 0.1266\n",
      "Epoch 19/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1291 - val_loss: 0.1216\n",
      "Epoch 20/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1220 - val_loss: 0.1178\n",
      "Epoch 21/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1184 - val_loss: 0.1175\n",
      "Epoch 22/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1216 - val_loss: 0.1197\n",
      "Epoch 23/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1194 - val_loss: 0.1176\n",
      "Epoch 24/30\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1162 - val_loss: 0.1168\n",
      "Epoch 25/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1155 - val_loss: 0.1126\n",
      "Epoch 26/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1157 - val_loss: 0.1195\n",
      "Epoch 27/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1138 - val_loss: 0.1155\n",
      "Epoch 28/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1147 - val_loss: 0.1126\n",
      "Epoch 29/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1143 - val_loss: 0.1138\n",
      "Epoch 30/30\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1129 - val_loss: 0.1145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdc42547630>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, day2_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_data = (X_val, val_day2_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.94      0.91       750\n",
      "         1.0       0.76      0.61      0.68       250\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.82      0.77      0.79      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.6\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (NUM_OF_VAL))\n",
    "y_pred = proba2onehot(y_pred, NUM_OF_VAL, THRESHOLD)\n",
    "print(classification_report(val_day2_labels, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 1, 200)            6120600   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 100)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 6,211,001\n",
      "Trainable params: 6,211,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=200, input_shape=(1, train_datas.shape[1]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"relu\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 20s 5ms/step - loss: 0.2151 - val_loss: 0.1699\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1693 - val_loss: 0.1495\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1490 - val_loss: 0.1376\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1461 - val_loss: 0.1295\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1367 - val_loss: 0.1295\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1285 - val_loss: 0.1290\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1270 - val_loss: 0.1267\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1216 - val_loss: 0.1312\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1197 - val_loss: 0.1240\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1170 - val_loss: 0.1188\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 14s 3ms/step - loss: 0.1195 - val_loss: 0.1240\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1192 - val_loss: 0.1255\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1192 - val_loss: 0.1275\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1152 - val_loss: 0.1223\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1139 - val_loss: 0.1222\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1143 - val_loss: 0.1228\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1125 - val_loss: 0.1311\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 15s 4ms/step - loss: 0.1139 - val_loss: 0.1282\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1117 - val_loss: 0.1224\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 14s 4ms/step - loss: 0.1093 - val_loss: 0.1313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa06a02da0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(train_datas, (train_datas.shape[0], 1, train_datas.shape[1]))\n",
    "X_val = np.reshape(val_datas, (val_datas.shape[0], 1, val_datas.shape[1]))\n",
    "model.fit(X_train, day7_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_data = (X_val, val_day7_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.87      0.88       776\n",
      "         1.0       0.59      0.65      0.62       224\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.74      0.76      0.75      1000\n",
      "weighted avg       0.83      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (NUM_OF_VAL))\n",
    "y_pred = proba2onehot(y_pred, NUM_OF_VAL, THRESHOLD)\n",
    "print(classification_report(val_day7_labels, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
